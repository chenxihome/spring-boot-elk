##kafka相关配置
#spring.kafka.bootstrap-servers=10.113.31.159:9092
##设置一个默认组
#spring.kafka.consumer.group-id=test-consumer-group
#spring.kafka.consumer.auto-offset-reset=earliest
#
##key-value序列化反序列化
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
##每次批量发送消息的数量
#spring.kafka.producer.batch-size=65536
#spring.kafka.producer.buffer-memory=524288
#zookeeper.address = 10.113.31.159:2181
#auto.create.topics.enable=true
#logging.level.root=debug




kafka.consumer.zookeeper.connect=10.113.31.159:2181
kafka.consumer.servers=10.113.31.159:9092
kafka.consumer.enable.auto.commit=true
kafka.consumer.session.timeout=6000
kafka.consumer.auto.commit.interval=100
kafka.consumer.auto.offset.reset=latest
kafka.consumer.topic=test
kafka.consumer.group.id=test
kafka.consumer.concurrency=10

kafka.producer.servers=10.113.31.159:9092
kafka.producer.retries=0
kafka.producer.batch.size=4096
kafka.producer.linger=1
kafka.producer.buffer.memory=40960